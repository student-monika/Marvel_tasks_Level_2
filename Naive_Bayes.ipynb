{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM30q64iSOL4sAy7JSbtJk3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/student-monika/Marvel_tasks_Level_2/blob/main/Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y76eSRE9lssB",
        "outputId": "bda32510-c07e-4e03-b28e-098f94a43959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 97.25%\n",
            "Message: 'Congratulations! You've won a free prize.' -> Prediction: Spam\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"spam.csv\"\n",
        "df = pd.read_csv(file_path, encoding='latin-1')\n",
        "\n",
        "# Keep only the relevant columns\n",
        "df = df[['v1', 'v2']]\n",
        "df.columns = ['label', 'message']\n",
        "\n",
        "# Encode labels: spam = 1, ham = 0\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Split data into features and labels\n",
        "messages = df['message'].values\n",
        "labels = df['label'].values\n",
        "\n",
        "# Tokenize and preprocess text\n",
        "def preprocess(text):\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Convert to lowercase and split into words\n",
        "    tokens = text.lower().split()\n",
        "    return tokens\n",
        "\n",
        "# Split data into training and testing sets\n",
        "def train_test_split(data, labels, test_size=0.3):\n",
        "    split_index = int(len(data) * (1 - test_size))\n",
        "    return data[:split_index], data[split_index:], labels[:split_index], labels[split_index:]\n",
        "\n",
        "# Train the classifier\n",
        "def train_naive_bayes(messages, labels):\n",
        "    # Separate messages by class\n",
        "    spam_messages = [messages[i] for i in range(len(labels)) if labels[i] == 1]\n",
        "    ham_messages = [messages[i] for i in range(len(labels)) if labels[i] == 0]\n",
        "\n",
        "    # Calculate prior probabilities\n",
        "    p_spam = len(spam_messages) / len(messages)\n",
        "    p_ham = len(ham_messages) / len(messages)\n",
        "\n",
        "    # Tokenize and count word frequencies\n",
        "    word_counts_spam = defaultdict(int)\n",
        "    word_counts_ham = defaultdict(int)\n",
        "\n",
        "    for message in spam_messages:\n",
        "        for word in preprocess(message):\n",
        "            word_counts_spam[word] += 1\n",
        "\n",
        "    for message in ham_messages:\n",
        "        for word in preprocess(message):\n",
        "            word_counts_ham[word] += 1\n",
        "\n",
        "    # Calculate total word counts\n",
        "    total_spam_words = sum(word_counts_spam.values())\n",
        "    total_ham_words = sum(word_counts_ham.values())\n",
        "\n",
        "    # Vocabulary\n",
        "    vocabulary = set(word_counts_spam.keys()).union(set(word_counts_ham.keys()))\n",
        "\n",
        "    return {\n",
        "        'p_spam': p_spam,\n",
        "        'p_ham': p_ham,\n",
        "        'word_counts_spam': word_counts_spam,\n",
        "        'word_counts_ham': word_counts_ham,\n",
        "        'total_spam_words': total_spam_words,\n",
        "        'total_ham_words': total_ham_words,\n",
        "        'vocabulary': vocabulary,\n",
        "    }\n",
        "\n",
        "# Predict if a message is spam or ham\n",
        "def predict(message, model, alpha=1):\n",
        "    # Tokenize the message\n",
        "    words = preprocess(message)\n",
        "\n",
        "    # Calculate log-probabilities\n",
        "    log_p_spam = np.log(model['p_spam'])\n",
        "    log_p_ham = np.log(model['p_ham'])\n",
        "\n",
        "    for word in words:\n",
        "        # Likelihood of the word in spam and ham messages\n",
        "        spam_likelihood = (model['word_counts_spam'][word] + alpha) / (model['total_spam_words'] + alpha * len(model['vocabulary']))\n",
        "        ham_likelihood = (model['word_counts_ham'][word] + alpha) / (model['total_ham_words'] + alpha * len(model['vocabulary']))\n",
        "\n",
        "        log_p_spam += np.log(spam_likelihood)\n",
        "        log_p_ham += np.log(ham_likelihood)\n",
        "\n",
        "    # Return the class with the highest probability\n",
        "    return 1 if log_p_spam > log_p_ham else 0\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "def evaluate_model(test_messages, test_labels, model):\n",
        "    predictions = [predict(message, model) for message in test_messages]\n",
        "    accuracy = np.mean(np.array(predictions) == np.array(test_labels))\n",
        "    return accuracy\n",
        "\n",
        "# Split the dataset\n",
        "train_messages, test_messages, train_labels, test_labels = train_test_split(messages, labels)\n",
        "\n",
        "# Train the model\n",
        "naive_bayes_model = train_naive_bayes(train_messages, train_labels)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = evaluate_model(test_messages, test_labels, naive_bayes_model)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Test with custom inputs\n",
        "test_message = \"Congratulations! You've won a free prize.\"\n",
        "print(f\"Message: '{test_message}' -> Prediction: {'Spam' if predict(test_message, naive_bayes_model) == 1 else 'Ham'}\")\n"
      ]
    }
  ]
}